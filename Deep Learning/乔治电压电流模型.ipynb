{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 train_loss:0.07502570748329163\n",
      "\n",
      "epoch:2 train_loss:0.02037825435400009\n",
      "\n",
      "epoch:3 train_loss:0.008092350326478481\n",
      "\n",
      "epoch:4 train_loss:0.005763792898505926\n",
      "\n",
      "epoch:5 train_loss:0.005267137195914984\n",
      "\n",
      "epoch:6 train_loss:0.005216540303081274\n",
      "\n",
      "TrueR= tensor([[5., 4., 3., 2., 1.]]) predicatedR= tensor([[4.9756, 3.9753, 2.9758, 1.9752, 0.9719]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "#生成需要的数据集和label对应的关系\n",
    "def generat_data(true_R,num_example,b):\n",
    "    #生成电流值 为0-1之间均匀分布的值\n",
    "    I=torch.rand(num_example,1)\n",
    "    U=torch.matmul(I,true_R)#U=IR\n",
    "    b=torch.normal(0,0.1,U.shape)\n",
    "    U+=b\n",
    "    return I,U\n",
    "\n",
    "def data_into_batch(I,U,batch_size):\n",
    "    num_u=len(U)\n",
    "    indices=list(range(num_u))\n",
    "    #将索引的顺序打乱\n",
    "    random.shuffle(indices)\n",
    "    #根据batchsize的大小将样本分组\n",
    "    for indice in range(0,num_u,batch_size):\n",
    "        batch_indices=torch.tensor(\n",
    "            indices[indice:min(indice+batch_size,num_u)]\n",
    "        )\n",
    "        yield I[batch_indices],U[batch_indices]\n",
    "#定义欧姆定律的模型 b是一个误差\n",
    "def model(I,R,b):\n",
    "    return torch.matmul(I,R)+b\n",
    "\n",
    "def loss(U_hat,U):\n",
    "    return (U_hat-U.reshape(U.shape))**2/2\n",
    "\n",
    "#随机梯度下降\n",
    "def sgd(params,learning_rate,batch_size):\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -=learning_rate*param.grad/batch_size\n",
    "            param.grad.zero_()\n",
    "\n",
    "#这是我们生成数据的时候用到的R\n",
    "true_R=torch.tensor([5.0,4.0,3.0,2.0,1.0]).reshape(1,-1)\n",
    "true_b=1.0\n",
    "\n",
    "I,U=generat_data(true_R,3000,true_b)\n",
    "learning_rate=0.1\n",
    "batch_size=30\n",
    "num_epochs=6\n",
    "\n",
    "#这是为我们需要寻找的R初始化\n",
    "R=torch.normal(0,0.01,size=true_R.shape,requires_grad=True)\n",
    "b=torch.zeros(1,requires_grad=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i,u, in  data_into_batch(I,U,batch_size):\n",
    "        l =loss(model(i,R,b),u)\n",
    "        l.sum().backward()\n",
    "        sgd([R,b],learning_rate,batch_size)\n",
    "    with torch.no_grad():\n",
    "        train_loss=loss(model(I,R,b),U)\n",
    "    print(f'epoch:{epoch+1} train_loss:{train_loss.mean()}\\n')\n",
    "\n",
    "print('TrueR=',true_R,'predicatedR=',R)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99c2b5feb3b0834ade928c2de885e167b0666d50604e2ef9e234d4eff7248b0b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('DeepLearning': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
