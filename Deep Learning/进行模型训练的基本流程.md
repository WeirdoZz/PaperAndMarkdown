# 进行模型训练的基本流程

## 数据预处理

### 获取标签的类别数

在对图像和标签进行预处理之前，需要先确定有多少个图像和标签 可以通过以下代码进行实现

`labels_dataframe.describe()`

他的意思是描述图片和标签的总个数和类别数以及出现频率最多的和出现的次数。也可以通过将标签所在列读取成集合来使其每个标签只出现一次，然后再通过len函数求出类别数代码如下:
```py
leaves_labels=sorted(list(set(labels_dataframe['label'])))
n_classes=len(leaves_labels)
```

为了方便之后的计算，可以将标签字符串转成对应的数字。代码如下：
```py
class_to_num=dict(zip(leaves_labels,range(n_classes)))
class_to_num
```

同样的还需要把他们转换回来，方便之后预测的时候进行转变。代码如下：
```py
num_to_class={v:k for k,v in class_to_num.items()}
```

### 进行数据集的处理
首先需要继承pytorch自己的Dataset类，在此基础上创建自己的类

通常来说，图像数据是放在单独文件夹中的，其文件名和对应的标签会放在csv文件中。所以init函数中大概需要四个参数

* csv文件的路径 csv_path
* 图像所在的文件路径 file_path
* 数据集创建的模式 mode
* 验证集的比例 valid_ratio

进行数据集的初始化的时候，其本质是对存有图片名称和对应标签的csv文件进行操作。根据csv文件中的内容长度可以确定训练集或者验证集或者测试集的长度，根据mode的不同给与的csv_path的内容也不同。其对应的代码如下：
```py
#继承一下pytorch的dataset 然后创建自己的新的数据集类
class LeavesData(Dataset):
    #定义初始化函数
    def __init__(self,csv_path,file_path,mode='train',valid_ratio=0.2,
                resize_height=256,resize_width=256) -> None:
        """
        Args:
            csv_path (string): csv 文件路径
            img_path (string): 图像文件所在路径
            mode (string): 训练模式还是测试模式
            valid_ratio (float): 验证集比例
        """
        super().__init__()
        #对类中的参数进行初始化
        self.resize_height=resize_height
        self.resize_width=resize_width

        self.file_path=file_path
        self.mode=mode

        #读取csv文件
        self.data_info=pd.read_csv(csv_path,header=None)#这里要去掉表头
        #计算数据的长度
        self.data_len=len(self.data_info.index)-1#因为表头没有设为header所以需要把表头去掉
        self.train_len=int(self.data_len*(1-valid_ratio))

        #如果是在训练模式下的话
        if mode=='train':
            #dataframe中的第一列是图像的名称 将他拿出来放到array中 由于header=none 所以真实的数据在索引为1的行
            self.train_image=np.asarray(self.data_info.iloc[1:self.train_len,0])
            #第二列是图像的标签
            self.train_label=np.asarray(self.data_info.iloc[1:self.train_len,1])

            self.image_arr=self.train_image
            self.label_arr=self.train_label
        #如果实在验证模式的情况下
        elif mode=='valid':
            self.valid_image=np.asarray(self.data_info.iloc[self.train_len:,0])
            self.valid_label=np.asarray(self.data_info.iloc[self.train_len:,1])

            self.image_arr=self.valid_image
            self.label_arr=self.valid_label
        #如果是在测试模式的情况下
        elif mode=='test':
            self.test_image=np.asarray(self.data_info.iloc[1:,0])
            self.image_arr=self.test_image
        
        self.real_len=len(self.image_arr)

        print('完成读取叶子数据集的{}集（发现{}个样本）'.format(mode,self.real_len))
```

为了能够通过索引获取到数据集的内容并且使其能够转换为迭代器类型，需要定义一个__getitem__函数，其需要设置一个index参数；还需要定义一个__len__参数，这是能够转换为迭代器类型的前提。

由于init函数中最终所读取到的其实是图像的名称，所以这时候之前初始化的file_path就派上用场了，用file_path+image_name就可以获取到对应的图像。通过`Image.open(self.file_path+single_image_name)`可以打开这个图像。

然后需要对图像进行数据增强操作，其中验证集和测试集是不需要的，只要在训练集上进行数据增强，这样训练出来的模型会更加好。根据mode参数确定当前载入的是哪个集。

如果是训练集或者验证集的话，这个函数会返回一个经过处理的图像和其对应的标签。其他模式的话直接返回这个图象。

代码如下：
```py
    #定义获取对应图像和标签的函数 如果是训练集或者验证集 返回值为图像和标签 如果是测试集返回值只有图像
    def __getitem__(self, index):
        #从image_arr 中获取索引对应的文件名
        single_image_name=self.image_arr[index]
        #根据获取到的文件名获取图像文件
        img_as_img=Image.open(self.file_path+single_image_name)

        #如果需要将rgb三通道图片转换为灰度图的话
        # if img_as_img.mode != 'L':
        #     img_as_img=img_as_img.convert('L')

        #设置好需要转换的变量 可以包括一系列的normalize等操作
        #如果是训练集的话可以做一下数据增强操作
        if self.mode=='train':
            transform=transforms.Compose([
                #重新设置尺寸
                transforms.Resize((224,224)),
                #以一个概率进行随机水平翻转
                transforms.RandomHorizontalFlip(p=0.5),
                transforms.ToTensor()
            ])
        else:#验证集和测试集不需要做数据增强
            transform=transforms.Compose([
                transforms.Resize((224,224)),
                transforms.ToTensor()
            ])
        
        #将transform应用到图像上
        img_as_img=transform(img_as_img)
        
        if self.mode=='test':
            return img_as_img
        else:
            #获取到图像的string label
            label=self.label_arr[index]
            #将string label对应到number label
            number_label=class_to_num[label]
            #返回每个img对应的标签
            return img_as_img,number_label

    #定义一个获取当前数据集数据个数的函数 无论是训练集 验证集还是测试集
    def __len__(self):
        return self.real_len
```

然后将数据集加载到数据集变量中。代码如下：

```py
train_path='../classify-leaves/train.csv'
test_path='../classify-leaves/test.csv'
#由于csv文件中有images的路径 这里只需要上一级的路径就可以了
img_path='../classify-leaves/'

train_dataset=LeavesData(train_path,img_path,mode='train')
valid_dataset=LeavesData(train_path,img_path,mode='valid')
test_dataset=LeavesData(test_path,img_path,mode='test')
```

之后需要将数据集放到数据加载器中，对它进行batchsize、shuffle等的设置。代码如下：

```py
#接下来定义数据加载器
train_loader=torch.utils.data.DataLoader(
    dataset=train_dataset,
    batch_size=8,
    shuffle=True,
    num_workers=0
)

valid_loader=torch.utils.data.DataLoader(
    dataset=valid_dataset,
    batch_size=8,
    shuffle=True,
    num_workers=0
)

test_loader=torch.utils.data.DataLoader(
    dataset=test_dataset,
    batch_size=8,
    shuffle=True,
    num_workers=0
)
```

**需要注意的是，这里面的num_workers如果不为0，则将其转换为iter的时候必须在main函数中才能运行**

## 模型训练

首先需要设置超参数。将相应的超参数和对应的值赋给变量。之后直接使用这个变量作为替代，当以后需要更改模型参数的时候，就可以直接更改这一个地方，其他地方就会自动更改了。最好还要设置一个模型保存的路径，这样可以在中途保存模型，也可以保存精度最好的一次训练得到的模型。

### 训练过程

* 先将模型设置为训练模式
* 将图像个对应的标签的张量去除
* 将图像张量放入模型中
* 计算损失
* 将优化器梯度清零
* 进行backward计算梯度
* 优化器前进