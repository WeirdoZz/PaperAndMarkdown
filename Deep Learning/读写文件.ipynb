{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到目前为止，我们讨论了如何处理数据，以及如何构建、训练和测试深度学习模型。然而，有时我们对所学的模型足够满意，我们希望保存训练的模型以备将来在各种环境中使用（甚至可能在部署中进行预测）。此外，当运行一个耗时较长的训练过程时，最佳的做法是定期保存中间结果（检查点），以确保在服务器电源被不小心断掉时不会损失几天的计算结果。因此，现在是时候学习如何加载和存储权重向量和整个模型。本节将讨论这些问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载和保存张量\n",
    "对于单个张量，可以直接调用load和save函数分别读写他们。这两个函数要求我们提供一个名称，save要求将要保存的变量作为输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =torch.arange(4)\n",
    "torch.save(x,'x-file')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 =torch.load('x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以存储一个张量列表，然后把他们读回内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y =torch.zeros(4)\n",
    "torch.save([x,y],'x-file')\n",
    "x2,y2 =torch.load('x-file')\n",
    "x2,y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们甚至可以写入或读取从字符串映射到张量的字典。当我们要读取或写入模型中的所有权重时，这很方便。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 1, 'y': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict ={'x':1,'y':2}\n",
    "torch.save(mydict,'mydict')\n",
    "mydict2 =torch.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载和保存模型数据\n",
    "保存单个权重向量（或其他张量）确实是有用的，但是如果我们想保存整个模型，并在以后加载它们，单独保存每个向量则会变得很麻烦。毕竟，我们可能有数百个参数散布在各处。因此，深度学习框架提供了内置函数来保存和加载整个网络。需要注意的一个重要细节是，这将<font color=\"Red\">这将保存模型的参数而不是保存整个模型</font>。例如，如果我们有一个3层多层感知机，我们需要单独指定结构。因为模型本身可以包含任意代码，所以模型本身难以序列化。因此，为了恢复模型，我们需要用代码生成结构，然后从磁盘加载参数。让我们从熟悉的多层感知机开始尝试一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden =nn.Linear(20,256)\n",
    "        self.out =nn.Linear(256,10)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "\n",
    "net =MLP()\n",
    "X=torch.randn(size=(2,20))\n",
    "Y =net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来将模型的参数存储为一个叫做mlp.params的文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight',\n",
       "              tensor([[ 0.2175,  0.1988,  0.1089,  ...,  0.1514,  0.0749,  0.2087],\n",
       "                      [ 0.1554, -0.2078,  0.0922,  ...,  0.0243,  0.1481,  0.0372],\n",
       "                      [ 0.0973,  0.1889,  0.1612,  ...,  0.0292,  0.0430, -0.1021],\n",
       "                      ...,\n",
       "                      [ 0.2136,  0.2220, -0.0263,  ...,  0.0389, -0.0835,  0.0212],\n",
       "                      [-0.0942,  0.1143, -0.1051,  ...,  0.1717,  0.1584, -0.0103],\n",
       "                      [-0.1927, -0.0554, -0.0049,  ..., -0.1432,  0.0686,  0.1330]])),\n",
       "             ('hidden.bias',\n",
       "              tensor([-0.1409,  0.0276, -0.0751, -0.0830,  0.1467,  0.0830, -0.0091,  0.0989,\n",
       "                       0.2019,  0.0361,  0.0194,  0.0333,  0.0781,  0.0566, -0.2188,  0.1257,\n",
       "                      -0.0580,  0.1853, -0.0258, -0.2179,  0.1819,  0.1162, -0.0924,  0.1058,\n",
       "                       0.0018, -0.0748, -0.1987,  0.0053, -0.1178,  0.0719,  0.1982,  0.0054,\n",
       "                      -0.0864,  0.0663, -0.2234, -0.0259, -0.0792,  0.0926,  0.2008, -0.0501,\n",
       "                       0.2101, -0.1743, -0.0577,  0.0422,  0.0091, -0.2159,  0.0728, -0.0839,\n",
       "                       0.1736, -0.1554, -0.1666, -0.0275, -0.1881,  0.0618, -0.0756, -0.1276,\n",
       "                       0.1089,  0.1670,  0.1404,  0.2138,  0.2141, -0.0829, -0.1947, -0.0737,\n",
       "                       0.1361, -0.1061,  0.0494,  0.0921, -0.0096,  0.1490, -0.0056, -0.0395,\n",
       "                      -0.2127,  0.0406, -0.0831, -0.2087,  0.0525,  0.0896,  0.0692, -0.1458,\n",
       "                      -0.2149,  0.1328,  0.1810, -0.0327, -0.1325, -0.0146,  0.2175, -0.1815,\n",
       "                      -0.1908,  0.0359,  0.0123,  0.0497,  0.1886,  0.0303, -0.2182,  0.0940,\n",
       "                      -0.1835,  0.0730, -0.0748,  0.1930, -0.0574,  0.0196, -0.1368,  0.0809,\n",
       "                      -0.2135,  0.2087, -0.1033, -0.1981,  0.1997,  0.1892,  0.1103, -0.0949,\n",
       "                      -0.1125, -0.1678,  0.0069, -0.0347, -0.0461,  0.1782,  0.0577,  0.1183,\n",
       "                       0.0886, -0.0128,  0.1354, -0.1287,  0.1329,  0.1919, -0.2069,  0.0790,\n",
       "                       0.0610,  0.1661,  0.1633, -0.0236, -0.0430,  0.0817, -0.1223,  0.1102,\n",
       "                       0.1914, -0.1948, -0.2071, -0.0735,  0.1441,  0.2221, -0.1862,  0.1159,\n",
       "                      -0.0670,  0.1376, -0.0732, -0.0169, -0.0920, -0.0702,  0.0688,  0.0514,\n",
       "                       0.0453,  0.1198, -0.1050,  0.2130, -0.1751, -0.0848, -0.0801,  0.1724,\n",
       "                       0.1636,  0.0717,  0.2005,  0.1764, -0.1886, -0.1504,  0.2072,  0.1036,\n",
       "                      -0.1779, -0.0378, -0.1001, -0.0206,  0.0701, -0.0075, -0.1198, -0.1125,\n",
       "                       0.1986,  0.1622,  0.0791,  0.0925,  0.0592, -0.1136,  0.0780,  0.1266,\n",
       "                      -0.0791, -0.0354,  0.0578,  0.1995,  0.0828,  0.1070, -0.1534,  0.0663,\n",
       "                       0.1257,  0.0726, -0.0722,  0.0560, -0.1781,  0.0253, -0.1704, -0.1528,\n",
       "                      -0.1354,  0.0700, -0.0998, -0.1871, -0.1336, -0.0434,  0.0035,  0.1457,\n",
       "                      -0.1414,  0.1593,  0.2172, -0.1521,  0.1146, -0.0314, -0.0581, -0.1618,\n",
       "                       0.0526, -0.1928, -0.0178, -0.2117, -0.2233,  0.0975, -0.1096,  0.0180,\n",
       "                      -0.0122,  0.1374, -0.2035, -0.1669,  0.1213,  0.1428, -0.1437, -0.1593,\n",
       "                      -0.0209,  0.0049, -0.0506, -0.2188, -0.1991, -0.0995, -0.0836, -0.1434,\n",
       "                      -0.1242,  0.1170, -0.0857,  0.1286,  0.1460,  0.1051, -0.1380,  0.0792,\n",
       "                      -0.1962,  0.0063, -0.2044,  0.1270,  0.0189, -0.1187, -0.0609, -0.0039])),\n",
       "             ('out.weight',\n",
       "              tensor([[ 0.0620, -0.0280, -0.0299,  ...,  0.0225, -0.0280, -0.0197],\n",
       "                      [-0.0597, -0.0144, -0.0055,  ..., -0.0370, -0.0591,  0.0623],\n",
       "                      [-0.0013, -0.0080,  0.0457,  ..., -0.0197, -0.0293,  0.0015],\n",
       "                      ...,\n",
       "                      [-0.0080, -0.0179, -0.0440,  ..., -0.0439, -0.0545, -0.0464],\n",
       "                      [ 0.0258, -0.0264, -0.0014,  ...,  0.0526,  0.0196, -0.0589],\n",
       "                      [-0.0071,  0.0380, -0.0340,  ..., -0.0559,  0.0008, -0.0336]])),\n",
       "             ('out.bias',\n",
       "              tensor([ 0.0272,  0.0197, -0.0071, -0.0066, -0.0399, -0.0128, -0.0596, -0.0307,\n",
       "                      -0.0276, -0.0582]))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()\n",
    "# net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),'mlp.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone=MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone=clone(X)\n",
    "Y_clone ==Y"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99c2b5feb3b0834ade928c2de885e167b0666d50604e2ef9e234d4eff7248b0b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('DeepLearning': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
