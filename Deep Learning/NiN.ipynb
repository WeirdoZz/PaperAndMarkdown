{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nin块的设计\n",
    "import torch \n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def nin_block(in_channels,out_chnnels,kernel_size,strides,padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels,out_chnnels,kernel_size,strides,padding),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(out_chnnels,out_chnnels,kernel_size=1),nn.ReLU(),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(out_chnnels,out_chnnels,kernel_size=1),nn.ReLU(),\n",
    "        nn.ReLU()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=nn.Sequential(\n",
    "    #初始输入的图像为(1,224,224)\n",
    "    #这一层之后输出的为(96,54,54)\n",
    "    nin_block(1,96,kernel_size=11,strides=4,padding=0),\n",
    "    #这一层之后输出为(96,26,26)\n",
    "    nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "    #这一层之后输出为(256,26,26)\n",
    "    nin_block(96,256,kernel_size=5,strides=1,padding=2),\n",
    "    #这一层输出之后为(256,12,12)\n",
    "    nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "    #这一层输出之后为(384,12,12)\n",
    "    nin_block(256,384,kernel_size=3,strides=1,padding=1),\n",
    "    #这一层之后输出为(384,5,5)\n",
    "    nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "    nn.Dropout(0.5),\n",
    "    #标签类别数是10 所以最后输出的通道数要为10\n",
    "    #这一层输出为(10,5,5)\n",
    "    nin_block(384,10,kernel_size=3,strides=1,padding=1),\n",
    "    nn.AdaptiveAvgPool2d((1,1)),\n",
    "    nn.Flatten(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 96, 54, 54])\n",
      "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
      "Sequential output shape:\t torch.Size([1, 256, 26, 26])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "Sequential output shape:\t torch.Size([1, 384, 12, 12])\n",
      "MaxPool2d output shape:\t torch.Size([1, 384, 5, 5])\n",
      "Dropout output shape:\t torch.Size([1, 384, 5, 5])\n",
      "Sequential output shape:\t torch.Size([1, 10, 5, 5])\n",
      "AdaptiveAvgPool2d output shape:\t torch.Size([1, 10, 1, 1])\n",
      "Flatten output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X=torch.rand(1,1,224,224)\n",
    "for layer in net:\n",
    "    X=layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#开始训练模型\n",
    "lr,num_epochs,batch_size=0.1,10,128\n",
    "train_iter,test_iter=d2l.load_data_fashion_mnist(batch_size,resize=224)\n",
    "d2l.train_ch6(net,train_iter,test_iter,num_epochs,lr,d2l.try_gpu())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99c2b5feb3b0834ade928c2de885e167b0666d50604e2ef9e234d4eff7248b0b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('DeepLearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
