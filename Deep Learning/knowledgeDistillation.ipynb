{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torchvision import datasets,transforms\n",
    "from tqdm import tqdm\n",
    "from d2l import torch as d2l\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先训练老师模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义老师模型的网络\n",
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(TeacherNet,self).__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Conv2d(1,32,3,1),nn.ReLU(),\n",
    "            nn.Conv2d(32,64,3,1),nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.3),nn.Flatten(),\n",
    "            nn.Linear(9216,128),nn.ReLU(),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.Linear(128,10),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_teacher(model,device,train_loader,optimizer,epoch):\n",
    "    model.train()\n",
    "    trained_samples=0\n",
    "    train_loss,train_acc=[],[]\n",
    "    \n",
    "    for batch_idx,(data,target) in enumerate(train_loader):\n",
    "        data,target=data.to(device),target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output=model(data)\n",
    "        loss=F.cross_entropy(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        trained_samples+=len(data)\n",
    "        progress=math.ceil(batch_idx/len(train_loader)*50)\n",
    "        print(\"\\rTrain epoch %d:%d/%d,[%-51s]%d%%\" % (epoch,trained_samples,len(train_loader.dataset),'-'*progress+'>',progress*2),end='')\n",
    "        # acc=(output.argmax(dim=-1)==target).float().mean()\n",
    "\n",
    "        # #记录损失和精度\n",
    "        # train_loss.append(loss.item())\n",
    "        # train_acc.append(acc)\n",
    "        # print(f'训练周期：{epoch+1:03d}/{num_epoch:03d} 训练损失：{train_loss:.5f} 训练精度：{train_acc:.5f}')\n",
    "\n",
    "def test_teacher(model,device,test_loader):\n",
    "    model.eval()\n",
    "    test_loss=0\n",
    "    correct=0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data,target in test_loader:\n",
    "            data,target =data.to(device),target.to(device)\n",
    "            output=model(data)\n",
    "            test_loss+=F.cross_entropy(output,target,reduction='sum').item()\n",
    "            pred=output.argmax(dim=1,keepdim=True)\n",
    "            correct+=pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss/=len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest:average loss:{:.4f},accuracy:{}/{} ({:.0f}%)'.format(test_loss,correct,len(test_loader.dataset),100.*correct/len(test_loader.dataset)))\n",
    "\n",
    "    return test_loss,correct/len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teacher_main():\n",
    "    num_epochs=10\n",
    "    batch_size=64\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_loader=torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(\"../data/MNIST\",train=True,download=\"True\",\n",
    "                        transform=transforms.Compose([\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.1307,),(0.3081,))\n",
    "        ])),\n",
    "        batch_size=batch_size,shuffle=True\n",
    "    )\n",
    "\n",
    "    test_loader=torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(\"../data/MNIST\",train=False,download=True,\n",
    "                        transform=transforms.Compose([\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.1307,),(0.3081,))\n",
    "        ])),\n",
    "        batch_size=1000,shuffle=True\n",
    "    )\n",
    "\n",
    "    model=TeacherNet().to(device)\n",
    "    optimizer=torch.optim.Adadelta(model.parameters())\n",
    "\n",
    "    teacher_history=[]\n",
    "    max_acc=0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_teacher(model,device,train_loader,optimizer,epoch)\n",
    "        loss,acc=test_teacher(model,device,test_loader)\n",
    "\n",
    "        teacher_history.append((loss,acc))\n",
    "        if acc>max_acc:\n",
    "            torch.save(model.state_dict(),\"teacher.pt\")\n",
    "            max_acc=acc\n",
    "    \n",
    "    return model,teacher_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 0:60000/60000,[-------------------------------------------------->]100%\n",
      "Test:average loss:0.0510,accuracy:9854/10000 (99%)\n",
      "Train epoch 1:60000/60000,[-------------------------------------------------->]100%\n",
      "Test:average loss:0.0406,accuracy:9871/10000 (99%)\n",
      "Train epoch 2:60000/60000,[-------------------------------------------------->]100%\n",
      "Test:average loss:0.0323,accuracy:9888/10000 (99%)\n",
      "Train epoch 3:60000/60000,[-------------------------------------------------->]100%\n",
      "Test:average loss:0.0352,accuracy:9883/10000 (99%)\n",
      "Train epoch 4:60000/60000,[-------------------------------------------------->]100%\n",
      "Test:average loss:0.0332,accuracy:9898/10000 (99%)\n",
      "Train epoch 5:60000/60000,[-------------------------------------------------->]100%\n",
      "Test:average loss:0.0313,accuracy:9908/10000 (99%)\n",
      "Train epoch 6:60000/60000,[-------------------------------------------------->]100%\n",
      "Test:average loss:0.0337,accuracy:9908/10000 (99%)\n",
      "Train epoch 7:60000/60000,[-------------------------------------------------->]100%\n",
      "Test:average loss:0.0313,accuracy:9911/10000 (99%)\n",
      "Train epoch 8:60000/60000,[-------------------------------------------------->]100%\n",
      "Test:average loss:0.0298,accuracy:9913/10000 (99%)\n",
      "Train epoch 9:60000/60000,[-------------------------------------------------->]100%\n",
      "Test:average loss:0.0315,accuracy:9915/10000 (99%)\n"
     ]
    }
   ],
   "source": [
    "teacher_model,teacher_history=teacher_main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cddc6a761772f09bdc816d4c8a9607d53bc5eb5813e332343549772becad59b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('DeepLearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
