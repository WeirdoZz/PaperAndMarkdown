{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(d2l.Encoder):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,dropout=0, **kwargs):\n",
    "        super(Seq2SeqEncoder,self).__init__(**kwargs)\n",
    "        #嵌入层\n",
    "        self.embedding=nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn=nn.GRU(embed_size,num_hiddens,num_layers,dropout=dropout)\n",
    "\n",
    "    def forward(self,X,*args):\n",
    "        #输出X的形状(batch_size,num_steps,embed_size)\n",
    "        X=self.embedding(X)\n",
    "        #在循环神经网络模型中，第一个轴对应于时间步\n",
    "        X=X.permute(1,0,2)\n",
    "        #如果没有提到状态，则默认为0\n",
    "        output,state=self.rnn(X)\n",
    "        # output的形状:(num_steps,batch_size,num_hiddens)\n",
    "        # state[0]的形状:(num_layers,batch_size,num_hiddens)\n",
    "        return output,state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 4, 16]), torch.Size([2, 4, 16]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder=Seq2SeqEncoder(vocab_size=10,embed_size=8,num_hiddens=16,num_layers=2)\n",
    "encoder.eval()\n",
    "X=torch.zeros((4,7),dtype=torch.long)\n",
    "output,state=encoder(X)\n",
    "output.shape,state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDecoder(d2l.Decoder):\n",
    "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,dropout=0, **kwargs):\n",
    "        super(Seq2SeqDecoder,self).__init__(**kwargs)\n",
    "        self.embedding=nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn=nn.GRU(embed_size+num_hiddens,num_hiddens,num_layers,dropout=dropout)\n",
    "        self.dense=nn.Linear(num_hiddens,vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        return enc_outputs[1]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        X=self.embedding(X).permute(1,0,2)\n",
    "        context=state[-1].repeat(X.shape[0],1,1)\n",
    "        X_and_Context=torch.cat((X,context),2)\n",
    "        output,state=self.rnn(X_and_Context,state)\n",
    "        output=self.dense(output).permute(1,0,2)\n",
    "        return output,state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7, 10]), torch.Size([2, 4, 16]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder=Seq2SeqDecoder(vocab_size=10,embed_size=8,num_hiddens=16,num_layers=2)\n",
    "decoder.eval()\n",
    "state=decoder.init_state(encoder(X))\n",
    "output,state=decoder(X,state)\n",
    "output.shape,state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [4, 5, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sequence_mask(X,valid_len,value=0):\n",
    "    maxlen=X.size(1)\n",
    "    mask=torch.arange((maxlen),dtype=torch.float32,device=X.device)[None,:]<valid_len[:,None]\n",
    "    X[~mask]=value\n",
    "    return X\n",
    "\n",
    "X=torch.tensor([[1,2,3],[4,5,6]])\n",
    "sequence_mask(X,torch.tensor([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  1.,  1.,  1.],\n",
       "         [-1., -1., -1., -1.],\n",
       "         [-1., -1., -1., -1.]],\n",
       "\n",
       "        [[ 1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.],\n",
       "         [-1., -1., -1., -1.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones(2, 3, 4)\n",
    "sequence_mask(X, torch.tensor([1, 2]), value=-1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "509613a040fc28972bc06b4d9c1a59b883185c0eaa84739b0195a1c7529c5004"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('DeepLearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
