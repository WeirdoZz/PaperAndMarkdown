<!--title: 无监督增量学习-->
- [摘要](#摘要)
- [引言](#引言)
- [方法](#方法)
  - [设定](#设定)
  - [检测训练](#检测训练)
  - [检测训练的类不平衡](#检测训练的类不平衡)
  - [模型和范例更新](#模型和范例更新)

## 摘要

尽管连续学习上的很多工作在减轻灾难性遗忘方面已经展现出了灿烂的前景，他们仍然是依靠监督训练。为了能够在无标签的增量情形下进行学习，模型必须要能够分别已经习得的类和新类从而能够准确地保留训练样本。

我们引入了一个新的检测方法，该方法利用了将输入数据训练为新类所引发的网络混乱。我们发现在这种方法中加入类不平衡可以很好地提升性能。

## 引言

持续学习系统的发展仍然是人工智能领域的一个主要问题。最初的挑战是减轻灾难性遗忘。这一领域的研究通常被称作持续学习，终生学习，连续学习，或者增量学习，每一个在学习环境和训练过程上都有微妙之处，但大多数使用监督学习

最近，Stojanov介绍了一个受到模仿孩童的玩耍行为如何影响他们学习对象模型能力需求的启发的新的无监督类增量学习问题。在这里，连续学习采取曝光的形式。每一个曝光由一组属于同一个类的图片组成，这个类是对学习器隐藏的。曝光的边界，也就是从一组曝光转变为另一组曝光的位置，学习器是知道的。在这种设定下训练的模型就类似于把小孩子放在有一组新玩具的游乐场。孩子会稳定地通过不断挑选、测试和放下新/旧玩具来获取信息。正如小孩不会有他们将要测试的玩具的指南一样，模型也无法在训练过程中接触到曝光的标签。

为了在无监督类增量情境下进行学习，模型必须成功完成两个步骤。对于给定的一个新的学习曝光，关键步骤是执行新类的检测：辨别出一个曝光是否与已经习得的类相关。如果学习器确定有一个曝光与之相似，则第二步就是去鉴定它的标签这样这个曝光就能够被用来更新模型。这两个步骤必须严密地执行，否则的话，新类检测错误会导致标签噪音从而干扰到学习到的模型，增加后续错误的可能性。

众所周知深度神经网络会对训练中未曾出现过的异常数据分布做出过度自信的决定。为了解决这一问题，异常分布检测相关的研究已经在使用监督学习方法和无监督学习方法了。开放集识别相关工作通过使用从已知类的得分计算出来的基于距离的阈值同样解决了这一问题。

与使用基于距离的尺度不一样，我们的新类检测阈值依赖通过输入的曝光更新模型所维持的准确率的百分比。这有几个实际优点：首先，阈值不依赖于监督样本并且更加直观；其次，方法的表现会独立于输入曝光的顺序。最后，模型能够更可靠地分辨相似类。

在我们的实验中，我们阐述了通过标签模糊训练得到的混乱与之前的方法相比会产生一个对于新类检测更可靠的信号。我们说明了我们的方法更加鲁棒并且在不同基准上的表现都很稳定。此外，尽管没有标签，我们的模型能够在多个基准下获得与监督学习相类似的表现。

作为总结，我们的工作有如下贡献

- 我们提出了一个新的框架，iLAP，能在没有标签的无监督类增量学习环境下进行学习。
- 我们阐述了通过使用类不平衡技术，我们的无监督方法在增量环境下训练的几个图像分类基准上能够获得与监督方法相近的表现
- 我们确定了利用基于距离的阈值的传统 OOD 方法忽略的故障案例。

## 方法

### 设定

在无监督类增量设定下，一个学习器L获取表示为E<sup>1</sup>,E<sup>2</sup>,...,E<sup>n</sup>的一组曝光输入流。每一个曝光都包含一组图片，E<sup>i</sup>={e<sup>i</sup><sub>1</sub>,e<sup>i</sup><sub>2</sub>,...,e<sup>i</sup><sub>n<sub>i</sub></sub>},e<sup>i</sup><sub>j</sub>∈R<sup>C×H×W</sup>，其中C,H,W是通道数、高度和宽度。每一组曝光都属于一个单独的类y<sub>i</sub>∈N,并且已经从类分布P(C)中采样了。对于每一个E<sup>i</sup>，L并不清楚它的真实标签类。训练集和验证集这两个范例始终保持维护。范例是用来存储曝光中为了之后的再现和准确率评估的样本。为了之后的再现和准确率评估。每个类的两个示例的大小都是有界的。

### 检测训练

对于给进的一个曝光，我们先试探性地赋予他一个新的类标签。对于模型我们做一个拷贝，在将新进来的样本分为训练集和验证集，与之前训练出来的类别继续训练拷贝出来的模型，之后用这次训练出来的之前的旧类的准确率和原始的准确率做比较，如果准确率下降超过一定的阈值，则新进来的样本是旧类;如果准确率的下降并未达到阈值，说明新进来的曝光确实是新类。如果是旧类的话，找到准确率下降最大的那个类别就是对应的这次输入的数据的类别。

### 检测训练的类不平衡

在检测训练中引入类不平衡会产生一个更加明显的决策边界，这是通过加剧对重复曝光的类的分类准确性下降实现的。考虑一个理论情况，最优的模型已经学习了k个类，这时输入进来的曝光是一个之前已经学习过的类，且数量和它差不多。如果通过将该类标记为k+1类来更新模型，则该类属于的真实类的预测准确率就会变得模糊，对于一个该类的样本，都有百分之50的可能分为正确类和第k+1类。但是，如果模型通过一个更大的样本更新，对于原本正确类的预测准确率就会下降的更厉害。

拷贝后的学习器可以选择在检测训练期间使用不平衡的数据集，其中新旧类的比例应该为$1-旧样本中该类样本数量/新样本中分出的训练集数量$

### 模型和范例更新

在获取到预测标签之后（无论是新类还是旧类），原L通过整合后的原训练集和新进曝光的训练集尽心训练。构造两个拥有新进曝光的训练集和测试集中最具有代表性的集合并且添加到各自的样例中以便之后使用。选择过程是通过对图像特征和样本均值特征之间的距离排序得到的。

验证集的可用性允许L评估新旧类的考虑程度。如果L中的任何一个类的准确率低于某个百分比，则将这个类从L中丢弃。这使得模型能够丢弃无关的类，这些类没有被充分学习到或者已经被遗忘。
