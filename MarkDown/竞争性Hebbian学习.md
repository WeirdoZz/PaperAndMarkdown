<<<<<<< HEAD
# Competitive Hebbian Learning Rule Forms Perfectly Topology Preserving Maps

## 摘要

完美构建特征流型的拓扑保持图的问题一直以来都在被研究。首先，通过引入“masked Voronoi polyhedra”作为决定流型上的邻接关系的集合结构来对术语“拓扑保持特征图”做一个严格的定义。定义表明，为了能够完美形成一个给定流型 $M\in R^D$ 的拓扑保持图，一个神经网络G的神经元1,...,i,...N之间会有连接结构A，$A_{ij}\in \left\{0,1\right\}$ 对应于突触权重向量 $w_i\in R^D$ 的“induced Delaunay triangulation”。这一连接决定了单元之间的连接关系，会**在流型上匹配特征的邻接关系**。如果所有的权重向量 $w_i$ 都分布在给定的特征流型上，并且这一分布能够解析M的形状，我们可以证明竞争赫布学习会在i和j之间产生连接，对应于“indeced Delaunay triangulation”中的边，因此就会生成一个网络结构来形成M的完美拓扑保持图，而且独立于M本身的拓扑。

## 引言

将输入的模式投射到一个网络上，这样相似的模式会被投射到相邻的单元上，即相邻的单元会编码相似的模式，这样就获得了输入模式的表征，使得研究者能在后处理阶段发掘输入模式之间的相似性。

一个提供了紧凑程序的模型并因此已经在人工神经信息处理系统中得到广泛应用的模型是Kohonen的自组织特征图。这个算法的要求是：首先选择一个网络图G，通常是1、2、3维的点阵；在之后的调整步骤中，被分配给节点（即神经元）i的指针（即突触权重向量）$w_i$ 以一种方式分布到流型 $M\subseteq R^D$ ,这种方式有两个要求：（1）指针在M中 （2）在图G中相邻的节点的指针被分配到M上相近的区域。

## 拓扑保持的精确定义

以一维向量做例子。两个点 $w_i,w_j \in R$ 在中间没有第三个点的情况下是邻近的。从维诺多面体来说，一个等价的定义是：两个点 $w_i,w_j \in R$ 是邻接的当维诺多面体 $V_i,V_j$ 是邻接的情况下。 $V_i$ 的定义如下：

$$
V_{i}=\left\{\mathbf{v} \in \Re^{D} \mid\left\|\mathbf{v}-\mathbf{w}_{i}\right\| \leq\left\|\mathbf{v}-\mathbf{w}_{j}\right\| j=1, \ldots, N\right\} \quad i=1, \ldots, N \tag{1}
$$

由于需要对流形上的点的邻居做出定义，我们首先引入掩维诺多面体的概念。掩维诺多面体 $V_i^{(M)}$ 是 $V_i$ 的一部分同时也是M的一部分，即 $V_i^{(M)}=V_i \bigcap M$ 。通过使用掩维诺多面体而非维诺多面体来定义M上点的邻接关系，我们确保两个点 $w_i,w_j$ 被称作邻接，当且仅当他们不属于M上不相连的区域。定义如下：

定义1：给定流形 $M \subseteq R^D$ 和集合 $S=\left\{w_1,...w_N\right\}$ 其中 $w_i \in M$ 。S的维诺多边形用 $V_i,i=1,...,N$ 表示。两个点 $w_i,w_j \in M \subseteq R^D$ ，若他们的掩维诺多面体 $V_i^{(M)}=V_i \bigcap M,V_j^{(M)}=V_j \bigcap M$ 在M上邻接,则 $w_i,w_j$ 邻接。 $V_i^{(M)},V_j^{(M)}$ 邻接的判断是他们存在交集就可以。

每一个掩维诺多面体是流形M的一部分，掩维诺多面体的集合形成一个流形M上的完整分区，比如 $M=\bigcup_{i=1}^{N} V_{i}^{(M)}$ 。

经过上面的定义，拓扑保持特征图可以准确被阐述出来：

定义2：G是一个带有节点i（神经元）的图（网络），i=1,...,N 并且边（侧连接）通过邻接矩阵A来定义， $A_{ij}\in \left\{0,1 \right\},i,j=1,...,N$ 。 $M \subseteq R^D$ 是给定的特征v的流形， $S=\left\{w_1,...,w_N\right\}$ 是指针（突触权重向量） $w_i \in M$ 集合，每一个指针都分配一个图G的节点i。将流形中的每一个特征v都映射到指针 $w_i$ 为离v最近的的节点i上。通过将节点分配给 $w_i$ ，图G形成了一个M的拓扑保持图。

## 将 Delaunay 三角剖分作为完美的拓扑保留图

假设被分配给图G中节点i的指针 $w_i,...,w_N$ 分布在给定的流形M上。当且仅当对应的掩维诺多面体是相邻的节点i,j被边i-j相连时，图G形成一个M的拓扑保持图。连接这些对应维诺多面体邻接的节点i，j的图结构就是Delaunay三角剖分。模仿这个定义我们基于掩维诺多面体定义了induced Delaunay 三角剖分：

定义3：给定流形 $M \subseteq R^D$ 和集合 $S=\left\{w_1,...w_N\right\}$ 其中 $w_i \in M$ 。S的induced Delaunay三角剖分 $D_S^{(M)}$ 由这样一个图定义，图中只有当节点 $w_I,w_j$ 的掩维诺多面体邻接的时候才会连接这两个点。比如说，一个图的邻接矩阵A，那么就有这样的属性：
$$
A_{ij}=1 \quad \Leftrightarrow \quad V_{i}^{(M)} \cap V_{j}^{(M)} \neq \emptyset \tag{2}
$$

下图对于以上定义做了一些解释，图中的流形M（阴影区域）是不相连的，每个 $w_i$ 的维诺多边形已经划好界限了。图（a）中的图G表示的是流形M的德劳内三角剖分（将相邻的维诺室中的 $w_i$ 相连）。图（b）没有形成一个拓扑保持图，因为其中由一部分相邻的节点之间并没有用边相连。图（c）中的图是最小生成树。图（d）是按照上述定义的induced 德劳内三角剖分.只有图d中形成了给定流形的完美拓扑保持图。

![picture 1](https://i.imgur.com/aLqnP8U.png)  

## 竞争性赫布规则

接下来我们模拟一组神经元从不连接到发展出连接的过程。横向连接通过一组连接强度矩阵C描述，其中元素 $C_{ij} \in R_0^+,i,j=1,...,N$ 。矩阵元素 $C_{ij}$ 越大则ij之间的连接就越强。只有当 $C_{ij} >0$ 时我们认为两个神经元是相连的。

根据赫布的假设，只有在突触前神经元和突触后神经元都处于活跃状态的情况下他们两之间的连接才会增强。用最简单的数学公式描述就是：

$$
\Delta C_{i j} \propto y_{i} \cdot y_{j} \tag{3}
$$

可以看出连接强度的变化是和两个神经元的活动成线性相关的。

对每个神经元i赋予一个权重向量 $w_i$ 。再假设每一个神经元i都接受相同的输入模式v。权重向量 $w_i$ 决定了神经元感受野的中心，在某种意义上来说神经元的输出活动随着v和 $w_i$ 的距离越近则活动越强烈。用数学的方式描述就是 $y_i=R(\|v-w_i\|)$ ，其中R()是一个正的并且连续单调递减的函数，比如高斯函数。

用公式(3)的形式来应用赫布规则会产生很无意义的结果，每一个神经元都会和别的神经元产生连接，并且连接强度只和 $R(\|v-w_i\|)$ 和 $R(\|v-w_j\|)$ 的感受野的重合部分相关。

与赢家通吃网络中的基于神经元本身的输出活动不同，在我们的模型中突触连接之间的竞争是由其两端神经元的输出活动 $Y_{ij}$ 相关的。在下面的公式中相关输出活动由 $Y_{ij}=y_i*y_j$ 决定。为了保持和赢家通吃网络相一致，输入一个v，只有 $Y_{ij}$ 值最大的两个节点会被调节。

$$
\Delta C_{i j} \propto \begin{cases}y_{i} \cdot y_{j} & \text { if } y_{i} \cdot y_{j} \geq y_{k} \cdot y_{l} \quad \forall k, l=1, \ldots N \\ 0 & \text { otherwise. }\end{cases} \tag{4}
$$

我们将会展示竞争性赫布规则会形成一个与权重向量相对应的德劳内三角剖分的连接结构而不是将每个神经元和其他神经元相连接。更准确地说就是，如果我们用一个分布P(v)来展示连续输入模式v，则所有连接强度矩阵都渐近地符合下式：

$$
\theta\left(C_{i j}(t \rightarrow \infty)\right)=A_{i j} \quad i, j=1, \ldots, N \tag{5}
$$

其中 $\theta ()$ 是重载阶跃函数。
=======
# Competitive Hebbian Learning Rule Forms Perfectly Topology Preserving Maps

## 摘要

完美构建特征流型的拓扑保持图的问题一直以来都在被研究。首先，通过引入“masked Voronoi polyhedra”作为决定流型上的邻接关系的集合结构来对术语“拓扑保持特征图”做一个严格的定义。定义表明，为了能够完美形成一个给定流型 $M\in R^D$ 的拓扑保持图，一个神经网络G的神经元1,...,i,...N之间会有连接结构A，$A_{ij}\in \left\{0,1\right\}$ 对应于突触权重向量 $w_i\in R^D$ 的“induced Delaunay triangulation”。这一连接决定了单元之间的连接关系，会**在流型上匹配特征的邻接关系**。如果所有的权重向量 $w_i$ 都分布在给定的特征流型上，并且这一分布能够解析M的形状，我们可以证明竞争赫布学习会在i和j之间产生连接，对应于“indeced Delaunay triangulation”中的边，因此就会生成一个网络结构来形成M的完美拓扑保持图，而且独立于M本身的拓扑。

## 引言

将输入的模式投射到一个网络上，这样相似的模式会被投射到相邻的单元上，即相邻的单元会编码相似的模式，这样就获得了输入模式的表征，使得研究者能在后处理阶段发掘输入模式之间的相似性。

一个提供了紧凑程序的模型并因此已经在人工神经信息处理系统中得到广泛应用的模型是Kohonen的自组织特征图。这个算法的要求是：首先选择一个网络图G，通常是1、2、3维的点阵；在之后的调整步骤中，被分配给节点（即神经元）i的指针（即突触权重向量）$w_i$ 以一种方式分布到流型 $M\subseteq R^D$ ,这种方式有两个要求：（1）指针在M中 （2）在图G中相邻的节点的指针被分配到M上相近的区域。

## 拓扑保持的精确定义

以一维向量做例子。两个点 $w_i,w_j \in R$ 在中间没有第三个点的情况下是邻近的。从维诺多面体来说，一个等价的定义是：两个点 $w_i,w_j \in R$ 是邻接的当维诺多面体 $V_i,V_j$ 是邻接的情况下。 $V_i$ 的定义如下：

$$
V_{i}=\left\{\mathbf{v} \in \Re^{D} \mid\left\|\mathbf{v}-\mathbf{w}_{i}\right\| \leq\left\|\mathbf{v}-\mathbf{w}_{j}\right\| j=1, \ldots, N\right\} \quad i=1, \ldots, N \tag{1}
$$

由于需要对流形上的点的邻居做出定义，我们首先引入掩维诺多面体的概念。掩维诺多面体 $V_i^{(M)}$ 是 $V_i$ 的一部分同时也是M的一部分，即 $V_i^{(M)}=V_i \bigcap M$ 。通过使用掩维诺多面体而非维诺多面体来定义M上点的邻接关系，我们确保两个点 $w_i,w_j$ 被称作邻接，当且仅当他们不属于M上不相连的区域。定义如下：

定义1：给定流形 $M \subseteq R^D$ 和集合 $S=\left\{w_1,...w_N\right\}$ 其中 $w_i \in M$ 。S的维诺多边形用 $V_i,i=1,...,N$ 表示。两个点 $w_i,w_j \in M \subseteq R^D$ ，若他们的掩维诺多面体 $V_i^(M)=V_i \bigcap M,V_j^(M)=V_j \bigcap M$ 在M上邻接,则 $w_i,w_j$ 邻接。 $V_i^(M),V_j^(M)$ 邻接的判断是他们存在交集就可以。

每一个掩维诺多面体是流形M的一部分，掩维诺多面体的集合形成一个流形M上的完整分区，比如 $M=\bigcup_{i=1}^{N} V_{i}^{(M)}$ 。

经过上面的定义，拓扑保持特征图可以准确被阐述出来：

定义2：G是一个带有节点i（神经元）的图（网络），i=1,...,N 并且边（侧连接）通过邻接矩阵A来定义， $A_ij \in \left\{0,1 \right\},i,j=1,...,N$ 。 $M \subseteq R^D$ 是给定的特征v的流形， $S=\left\{w_1,...,w_N\right\}$ 是指针（突触权重向量） $w_i \in M$ 集合，每一个指针都分配一个图G的节点i。将流形中的每一个特征v都映射到指针 $w_i$ 为离v最近的的节点i上。通过将节点分配给 $w_i$ ，图G形成了一个M的拓扑保持图。

## 将 Delaunay 三角剖分作为完美的拓扑保留图

假设被分配给图G中节点i的指针 $w_i,...,w_N$ 分布在给定的流形M上。当且仅当对应的掩维诺多面体是相邻的节点i,j被边i-j相连时，图G形成一个M的拓扑保持图。连接这些对应维诺多面体邻接的节点i，j的图结构就是Delaunay三角剖分。模仿这个定义我们基于掩维诺多面体定义了induced Delaunay 三角剖分：

定义3：给定流形 $M \subseteq R^D$ 和集合 $S=\left\{w_1,...w_N\right\}$ 其中 $w_i \in M$ 。S的induced Delaunay三角剖分 $D_S^(M)$ 由这样一个图定义，图中只有当节点 $w_I,w_j$ 的掩维诺多面体邻接的时候才会连接这两个点。比如说，一个图的邻接矩阵A，那么就有这样的属性：
$$
A_{ij}=1 \quad \Leftrightarrow \quad V_{i}^{(M)} \cap V_{j}^{(M)} \neq \emptyset \tag{2}
$$
>>>>>>> fc955cd81629070abc41337686d168bd30f395c4
